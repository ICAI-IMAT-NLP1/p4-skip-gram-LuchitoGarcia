{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'hello', 1: 'world', 2: 'test'}\n",
      "{'hello': 0, 'world': 1, 'test': 2}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "words = [\"hello\", \"world\", \"hello\", \"test\"]\n",
    "word_counts: Counter = Counter(words)\n",
    "    # Sorting the words from most to least frequent in text occurrence.\n",
    "sorted_vocab = sorted(word_counts, key = word_counts.get, reverse=True)\n",
    "\n",
    "int_to_vocab = {i: word for i, word in enumerate(sorted_vocab)}\n",
    "vocab_to_int = {word:i for i,word in enumerate(sorted_vocab)}\n",
    "\n",
    "\n",
    "print(int_to_vocab)\n",
    "print(vocab_to_int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apple': 2, 'banana': 3, 'cherry': 1, 'date': 1}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [\"apple\", \"banana\", \"cherry\", \"date\", \"apple\", \"banana\", \"banana\"]\n",
    "threshold: float = 1e-5\n",
    "import math\n",
    "vocab_to_int = {\"apple\": 0, \"banana\": 1, \"cherry\": 2, \"date\": 3}\n",
    "int_words= []\n",
    "for word in words:\n",
    "    int_words.append(vocab_to_int[word])\n",
    "\n",
    "\n",
    "freqs = {}\n",
    "probs = {}\n",
    "train_words = []\n",
    "\n",
    "for word in words:\n",
    "    if word not in freqs:\n",
    "        freqs[word] = 1\n",
    "    else:\n",
    "        freqs[word] += 1\n",
    "\n",
    "for i in range(len(words)):\n",
    "    word = words[i]\n",
    "    if word not in probs:\n",
    "        probs[word] = 1 - math.sqrt(threshold / freqs[word])\n",
    "\n",
    "train_words = [word for word in words if probs[word] >= 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple', 'banana', 'cherry', 'apple', 'banana', 'banana']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [\"apple\", \"banana\", \"cherry\", \"date\", \"apple\", \"banana\", \"banana\"]\n",
    "c = 3\n",
    "a = []\n",
    "for i in range(2*c + 1):\n",
    "    if i != c:\n",
    "        a.append(words[i])\n",
    "a\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['brown', 'fox', 'jumps', 'over', 'lazy', 'dog']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "words = [\"the\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"the\", \"lazy\", \"dog\"]\n",
    "idx = 6 # For the word \"jumps\"\n",
    "window_size = 5  # Test with a smaller window\n",
    "\n",
    "window = random.randint(1,window_size)\n",
    "print(window)\n",
    "\n",
    "left = words[max(idx-window, 0) : idx]\n",
    "right = words[idx + 1 : idx + 1 + window]\n",
    "\n",
    "\n",
    "left + right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/71/l1gpfd6j731c1qxy1_l8ffvh0000gn/T/ipykernel_51772/1188014681.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_vectors: torch.Tensor = torch.tensor(input_words)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from src.skipgram import SkipGramNeg\n",
    "n_vocab = 100\n",
    "n_embed = 50\n",
    "model = SkipGramNeg(n_vocab, n_embed)\n",
    "input_words = torch.randint(0, n_vocab, (10,))  # A batch of 10 random word indices\n",
    "input_vectors: torch.Tensor = torch.tensor(input_words)\n",
    "model.forward_input(input_words)\n",
    "\n",
    "input_vectors.shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
